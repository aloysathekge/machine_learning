{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Telco Churn Model\n",
        "\n",
        "**What we're doing:** We have data on 7,043 telecom customers. Some stayed, some left (churned). We want to build a model that looks at a customer's behaviour and predicts: will this person leave?\n",
        "\n",
        "**Why it matters:** If we can predict who will leave BEFORE they leave, we can offer them something to stay. That saves the company money because keeping a customer is cheaper than finding a new one."
      ],
      "id": "064e8b16"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "069c7793"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load and look at the data\n",
        "\n",
        "Always start by understanding what you're working with. How many customers? What columns? What does a row look like?"
      ],
      "id": "c27bba3c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
        "print(f\"We have {len(df)} customers and {len(df.columns)} columns\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "be47743e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Clean the data\n",
        "\n",
        "Two things to fix:\n",
        "1. **TotalCharges** has some blank values (stored as spaces). We convert to numbers and fill blanks with the median.\n",
        "2. **Churn** is \"Yes\"/\"No\" but models need numbers. We convert to 1/0."
      ],
      "id": "a6721265"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "df[\"TotalCharges\"].fillna(df[\"TotalCharges\"].median(), inplace=True)\n",
        "\n",
        "df[\"Churn\"] = df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
        "\n",
        "print(f\"Churn rate: {df['Churn'].mean():.1%}\")\n",
        "print(f\"That means {df['Churn'].sum()} out of {len(df)} customers left\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "be61fb50"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Explore — who churns and why?\n",
        "\n",
        "Before building a model, we look at patterns. Three questions:\n",
        "1. Do new customers churn more than long-term ones?\n",
        "2. Does contract type matter?\n",
        "3. Do higher-paying customers churn more?"
      ],
      "id": "755ed54f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
        "\n",
        "# Question 1: Tenure (how long they've been a customer)\n",
        "axes[0].hist(df[df[\"Churn\"] == 0][\"tenure\"], bins=20, alpha=0.7, label=\"Stayed\", color=\"green\")\n",
        "axes[0].hist(df[df[\"Churn\"] == 1][\"tenure\"], bins=20, alpha=0.7, label=\"Left\", color=\"red\")\n",
        "axes[0].set_title(\"Tenure: New customers leave more\")\n",
        "axes[0].set_xlabel(\"Months as customer\")\n",
        "axes[0].legend()\n",
        "\n",
        "# Question 2: Contract type\n",
        "contract_churn = df.groupby(\"Contract\")[\"Churn\"].mean()\n",
        "axes[1].bar(contract_churn.index, contract_churn.values, color=[\"red\", \"orange\", \"green\"])\n",
        "axes[1].set_title(\"Churn rate by contract type\")\n",
        "axes[1].set_ylabel(\"Churn rate\")\n",
        "\n",
        "# Question 3: Monthly charges\n",
        "axes[2].boxplot(\n",
        "    [df[df[\"Churn\"] == 0][\"MonthlyCharges\"], df[df[\"Churn\"] == 1][\"MonthlyCharges\"]],\n",
        "    labels=[\"Stayed\", \"Left\"]\n",
        ")\n",
        "axes[2].set_title(\"Churners pay more per month\")\n",
        "axes[2].set_ylabel(\"Monthly charges ($)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "f20be520"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Prepare features for the model\n",
        "\n",
        "A model only understands numbers. So we need to:\n",
        "1. **Pick which columns to use** — we drop customerID (just an ID, no predictive value) and Churn (that's what we're predicting)\n",
        "2. **Convert text columns to numbers** — \"Male\"/\"Female\" becomes 1/0, \"Month-to-month\"/\"One year\"/\"Two year\" becomes separate columns using one-hot encoding\n",
        "3. **Scale the numbers** — tenure is 0-72, MonthlyCharges is 18-118. Without scaling, the model thinks MonthlyCharges matters more just because the numbers are bigger. Scaling puts everything on the same range."
      ],
      "id": "f46213f1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# X = the information we give the model (features)\n",
        "# y = the answer we want the model to predict (churn: 1 or 0)\n",
        "\n",
        "X = df.drop(columns=[\"customerID\", \"Churn\"])\n",
        "y = df[\"Churn\"]\n",
        "\n",
        "# Convert text columns to numbers using one-hot encoding\n",
        "# Example: Contract has 3 values -> becomes 3 separate columns, each 0 or 1\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "print(f\"Features: {X.shape[1]} columns\")\n",
        "print(f\"Target: {len(y)} values ({y.sum()} churned, {(y==0).sum()} stayed)\")\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "5996dd6b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Split into training and testing sets\n",
        "\n",
        "**Why split?** We need to test the model on data it has NEVER seen. If we test on the same data we trained on, it's like giving a student the exam answers and then testing them — of course they'll score well, but they haven't learned anything.\n",
        "\n",
        "- **Training set (80%)** — the model learns patterns from this\n",
        "- **Test set (20%)** — we check if the model actually works on this\n",
        "\n",
        "**stratify=y** means we keep the same churn ratio in both sets. If 26% churned overall, both sets will have ~26% churners."
      ],
      "id": "b29a5d12"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Scale the numbers so all features are on the same range\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"Training: {len(X_train)} customers\")\n",
        "print(f\"Testing:  {len(X_test)} customers\")\n",
        "print(f\"Training churn rate: {y_train.mean():.1%}\")\n",
        "print(f\"Testing churn rate:  {y_test.mean():.1%}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "63d8724e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Train Model 1 — Logistic Regression (the simple one)\n",
        "\n",
        "**What is Logistic Regression?** It draws a line between churners and non-churners. For each customer it outputs a probability between 0 and 1. A score of 0.8 means \"80% chance this customer will churn.\"\n",
        "\n",
        "**Why start here?** It's simple, fast, and interpretable. If a simple model works well, you don't need a complex one. It's our **baseline** — the minimum standard the next model must beat.\n",
        "\n",
        "**class_weight=\"balanced\"** — Our data has 26% churners and 74% non-churners. Without this, the model might just predict \"no churn\" for everyone and be right 74% of the time — but it would miss every single churner. Setting `balanced` tells the model: \"Pay extra attention to the churners, they matter more.\""
      ],
      "id": "62515fb3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lr_model = LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=42)\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# The model now gives each test customer a churn probability\n",
        "lr_probabilities = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Look at some example predictions\n",
        "examples = pd.DataFrame({\n",
        "    \"Actual\": y_test.values[:10],\n",
        "    \"Churn Probability\": lr_probabilities[:10].round(3)\n",
        "})\n",
        "print(\"First 10 predictions:\")\n",
        "print(examples.to_string(index=False))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "1b115a40"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Evaluate — how good is our model?\n",
        "\n",
        "### The Confusion Matrix — counting right and wrong predictions\n",
        "\n",
        "The model gives a probability. To make a yes/no decision, we pick a **threshold** (default 0.5):\n",
        "- Probability >= 0.5 → predict \"will churn\"\n",
        "- Probability < 0.5 → predict \"will stay\"\n",
        "\n",
        "Then we count four outcomes:\n",
        "\n",
        "|  | Predicted: Stay | Predicted: Churn |\n",
        "|---|---|---|\n",
        "| **Actually Stayed** | **True Negative (TN)** — Correct! | **False Positive (FP)** — Wrong. We'd waste money offering them something they didn't need |\n",
        "| **Actually Churned** | **False Negative (FN)** — Wrong. We MISSED a churner. They left and we did nothing | **True Positive (TP)** — Correct! We caught a churner |\n",
        "\n",
        "From this we get three important numbers:\n",
        "\n",
        "- **Precision** = TP / (TP + FP) = \"Of everyone we flagged as churners, how many actually churned?\" High precision = fewer wasted offers\n",
        "- **Recall** = TP / (TP + FN) = \"Of all actual churners, how many did we catch?\" High recall = fewer missed churners\n",
        "- **F1 Score** = the balance between precision and recall. It's their harmonic mean. If either precision OR recall is bad, F1 will be bad too"
      ],
      "id": "fe4dd3bd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Convert probabilities to yes/no predictions using 0.5 threshold\n",
        "lr_predictions = (lr_probabilities >= 0.5).astype(int)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, lr_predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(f\"  True Negatives  (correctly said 'stay'):  {cm[0][0]}\")\n",
        "print(f\"  False Positives (wrongly said 'churn'):   {cm[0][1]}\")\n",
        "print(f\"  False Negatives (missed churners):        {cm[1][0]}\")\n",
        "print(f\"  True Positives  (caught churners):        {cm[1][1]}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, lr_predictions, target_names=[\"Stayed\", \"Churned\"]))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "b5939066"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AUC-ROC — how well does the model RANK customers?\n",
        "\n",
        "**The problem with a single threshold:** Using 0.5 as the cutoff is arbitrary. What if 0.3 works better? What if 0.7?\n",
        "\n",
        "**ROC Curve** answers: \"How well does the model separate churners from non-churners across ALL possible thresholds?\"\n",
        "\n",
        "It plots:\n",
        "- **X-axis: False Positive Rate** — what % of non-churners are we wrongly flagging?\n",
        "- **Y-axis: True Positive Rate (Recall)** — what % of actual churners are we catching?\n",
        "\n",
        "A perfect model hugs the top-left corner. A random guess is the diagonal line.\n",
        "\n",
        "**AUC = Area Under the Curve** — a single number between 0 and 1:\n",
        "- **1.0** = perfect model (catches every churner, never flags a non-churner)\n",
        "- **0.5** = random coin flip (useless)\n",
        "- **0.8+** = good model\n",
        "\n",
        "**Why AUC matters more than accuracy:** In the interview, if they ask \"why not just use accuracy?\" — say: \"Because with 74% non-churners, a model that predicts 'stay' for everyone gets 74% accuracy but catches zero churners. AUC measures ranking quality regardless of the threshold.\""
      ],
      "id": "4f7b428f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lr_auc = roc_auc_score(y_test, lr_probabilities)\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, lr_probabilities)\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.plot(fpr, tpr, color=\"blue\", lw=2, label=f\"Logistic Regression (AUC = {lr_auc:.3f})\")\n",
        "plt.plot([0, 1], [0, 1], \"k--\", lw=1, label=\"Random guess (AUC = 0.500)\")\n",
        "plt.xlabel(\"False Positive Rate (wrongly flagged non-churners)\")\n",
        "plt.ylabel(\"True Positive Rate (correctly caught churners)\")\n",
        "plt.title(\"ROC Curve — Logistic Regression\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f\"AUC-ROC: {lr_auc:.3f}\")\n",
        "print(f\"This means the model ranks a random churner above a random non-churner {lr_auc:.0%} of the time\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "88676d8b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Train Model 2 — XGBoost (the powerful one)\n",
        "\n",
        "**What is XGBoost?** It builds many small decision trees, one after another. Each new tree focuses on the mistakes the previous trees made. It's like a team of weak students who each learn from the previous student's errors — together they become strong.\n",
        "\n",
        "**Why use it?** Logistic Regression draws a straight line. But real patterns aren't always straight. XGBoost captures complex patterns like: \"customers who have month-to-month contracts AND are new AND pay a lot — those churn the most.\" It finds combinations that Logistic Regression can't.\n",
        "\n",
        "**scale_pos_weight** does the same job as `class_weight=\"balanced\"` — it tells XGBoost to pay more attention to churners."
      ],
      "id": "96902e46"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ratio of non-churners to churners (about 2.7 to 1)\n",
        "imbalance_ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=4,\n",
        "    learning_rate=0.05,\n",
        "    scale_pos_weight=imbalance_ratio,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric=\"auc\"\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "xgb_probabilities = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
        "xgb_predictions = (xgb_probabilities >= 0.5).astype(int)\n",
        "xgb_auc = roc_auc_score(y_test, xgb_probabilities)\n",
        "\n",
        "print(f\"Logistic Regression AUC: {lr_auc:.3f}\")\n",
        "print(f\"XGBoost AUC:             {xgb_auc:.3f}\")\n",
        "print(f\"Improvement:             {xgb_auc - lr_auc:+.3f}\")\n",
        "print(f\"\\nXGBoost Classification Report:\")\n",
        "print(classification_report(y_test, xgb_predictions, target_names=[\"Stayed\", \"Churned\"]))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "cd624fdf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: What features matter most?\n",
        "\n",
        "This answers the interview question: \"What drives churn?\" The model tells us which features had the most influence on its predictions."
      ],
      "id": "f36aea77"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "importance = pd.Series(xgb_model.feature_importances_, index=X.columns)\n",
        "top_10 = importance.sort_values(ascending=True).tail(10)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "top_10.plot(kind=\"barh\", color=\"steelblue\")\n",
        "plt.title(\"Top 10 Features Driving Churn Prediction\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "14058db2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Segmentation — who gets what offer?\n",
        "\n",
        "### What is segmentation?\n",
        "\n",
        "**Segmentation** means dividing customers into groups so you can treat each group differently.\n",
        "\n",
        "Think of it like a hospital triage:\n",
        "- A patient with a broken finger and a patient with a heart attack both need help\n",
        "- But you don't give them the same treatment, and you don't treat them with the same urgency\n",
        "\n",
        "Same with churn:\n",
        "- A customer who spends $100/month and is about to leave → give them your best retention offer (they're worth saving)\n",
        "- A customer who spends $20/month and is about to leave → send them a text message at most (not worth an expensive offer)\n",
        "- A customer who spends $100/month and is happy → don't waste a retention offer on them (they're not leaving)\n",
        "\n",
        "We create a **2x2 matrix** using:\n",
        "1. **Risk** — how likely are they to churn? (from the model's probability score)\n",
        "2. **Value** — how much do they spend? (from their MonthlyCharges)"
      ],
      "id": "88c601ff"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Score every customer\n",
        "df[\"churn_score\"] = xgb_model.predict_proba(scaler.transform(pd.get_dummies(df.drop(columns=[\"customerID\", \"Churn\"]), drop_first=True)))[:, 1]\n",
        "\n",
        "# Divide into risk groups\n",
        "df[\"risk\"] = \"Low Risk\"\n",
        "df.loc[df[\"churn_score\"] >= 0.5, \"risk\"] = \"High Risk\"\n",
        "\n",
        "# Divide into value groups\n",
        "median_spend = df[\"MonthlyCharges\"].median()\n",
        "df[\"value\"] = \"Low Value\"\n",
        "df.loc[df[\"MonthlyCharges\"] >= median_spend, \"value\"] = \"High Value\"\n",
        "\n",
        "# Create segment\n",
        "df[\"segment\"] = df[\"risk\"] + \" + \" + df[\"value\"]\n",
        "\n",
        "# Count customers in each segment\n",
        "segment_table = df.groupby(\"segment\").agg(\n",
        "    customers=(\"customerID\", \"count\"),\n",
        "    avg_churn_score=(\"churn_score\", \"mean\"),\n",
        "    avg_monthly_spend=(\"MonthlyCharges\", \"mean\"),\n",
        "    actual_churn_rate=(\"Churn\", \"mean\")\n",
        ").round(3)\n",
        "\n",
        "print(\"Customer Segments:\")\n",
        "print(segment_table)\n",
        "print(f\"\\nMedian monthly spend (split point): ${median_spend:.0f}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "c50d693f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualise: scatter plot of all customers by risk and value\n",
        "plt.figure(figsize=(9, 6))\n",
        "\n",
        "colors = {\n",
        "    \"High Risk + High Value\": \"red\",\n",
        "    \"High Risk + Low Value\": \"orange\",\n",
        "    \"Low Risk + High Value\": \"green\",\n",
        "    \"Low Risk + Low Value\": \"lightgreen\"\n",
        "}\n",
        "\n",
        "for segment, color in colors.items():\n",
        "    mask = df[\"segment\"] == segment\n",
        "    plt.scatter(\n",
        "        df[mask][\"MonthlyCharges\"],\n",
        "        df[mask][\"churn_score\"],\n",
        "        c=color, label=f\"{segment} ({mask.sum()})\", alpha=0.4, s=10\n",
        "    )\n",
        "\n",
        "plt.axhline(y=0.5, color=\"black\", linestyle=\"--\", lw=1, label=\"Risk threshold (0.5)\")\n",
        "plt.axvline(x=median_spend, color=\"black\", linestyle=\":\", lw=1, label=f\"Value threshold (${median_spend:.0f})\")\n",
        "plt.xlabel(\"Monthly Charges ($) — Customer Value\")\n",
        "plt.ylabel(\"Churn Probability — Risk Score\")\n",
        "plt.title(\"Customer Segmentation: Risk vs Value\")\n",
        "plt.legend(loc=\"upper left\", fontsize=9)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "0111641e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Business recommendations — what we'd actually DO\n",
        "\n",
        "This is the part that matters in the interview. The model is just a tool. What matters is the **decision** it enables."
      ],
      "id": "1567bfc1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "OFFER_COST = 30       # cost of a retention offer per customer\n",
        "CUSTOMER_VALUE = 200  # average value of keeping a customer for 90 days\n",
        "SAVE_RATE = 0.40      # 40% of offered customers actually stay\n",
        "\n",
        "for segment in [\"High Risk + High Value\", \"High Risk + Low Value\", \"Low Risk + High Value\", \"Low Risk + Low Value\"]:\n",
        "    seg = df[df[\"segment\"] == segment]\n",
        "    n = len(seg)\n",
        "    churners = seg[\"Churn\"].sum()\n",
        "\n",
        "    if \"High Risk\" in segment:\n",
        "        saved = int(churners * SAVE_RATE)\n",
        "        cost = n * OFFER_COST\n",
        "        revenue = saved * CUSTOMER_VALUE\n",
        "        profit = revenue - cost\n",
        "\n",
        "        print(f\"\\n{segment}: {n} customers, {churners} would churn\")\n",
        "        print(f\"  If we offer all of them a ${OFFER_COST} retention deal:\")\n",
        "        print(f\"  Cost:    ${cost:,}\")\n",
        "        print(f\"  Saved:   {saved} customers\")\n",
        "        print(f\"  Revenue: ${revenue:,}\")\n",
        "        print(f\"  Profit:  ${profit:,} {'(worth it!)' if profit > 0 else '(not worth it)'}\")\n",
        "    else:\n",
        "        print(f\"\\n{segment}: {n} customers, {churners} would churn\")\n",
        "        print(f\"  Action: No retention offer needed (low risk)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"KEY INSIGHT: We only spend money on high-risk customers.\")\n",
        "print(\"The model tells us WHO to spend on, so we don't waste money\")\n",
        "print(\"on customers who would have stayed anyway.\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4d595142"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary — what to say in the interview\n",
        "\n",
        "**\"What did you build?\"**\n",
        "A churn prediction model that scores every customer on their likelihood to leave, then segments them by risk and value to recommend who gets a retention offer and who doesn't.\n",
        "\n",
        "**\"Why not just use accuracy?\"**\n",
        "Because accuracy rewards predicting the majority class. A model that says \"nobody will churn\" gets 74% accuracy but catches zero churners. AUC-ROC measures how well the model ranks customers, regardless of the threshold.\n",
        "\n",
        "**\"What is F1?\"**\n",
        "The balance between precision (are my flags accurate?) and recall (did I catch most churners?). If either is bad, F1 is bad.\n",
        "\n",
        "**\"What is segmentation?\"**\n",
        "Dividing customers into groups based on risk and value, so we give expensive offers to high-value customers at risk, cheap nudges to low-value ones at risk, and nothing to customers who are fine.\n",
        "\n",
        "**\"How do you prove it works?\"**\n",
        "Hold out 10% of high-risk customers as a control group — they get no offer. After 90 days, compare churn rates. The difference is the incremental lift — the true value the model created."
      ],
      "id": "1e0eb082"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}